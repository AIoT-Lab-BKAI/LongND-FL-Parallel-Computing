
log/iid/fedavg
Train :------------------------------
[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
Client : 2 Number sample : 20 Epoch : 0   Ep loss : 2.307834267616272
Client : 2 Number sample : 20 Epoch : 1   Ep loss : 1.9760512709617615
Client : 2 Number sample : 20 Epoch : 2   Ep loss : 1.591066598892212
100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 45.95it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 126.94it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 318.02it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 162.43it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 120.43it/s]
Client : 2 Number sample : 20 Epoch : 3   Ep loss : 1.28524512052536
Client : 2 Number sample : 20 Epoch : 4   Ep loss : 1.027978539466858
Client : 3 Number sample : 20 Epoch : 0   Ep loss : 2.297292947769165
Client : 3 Number sample : 20 Epoch : 1   Ep loss : 1.9438087940216064
Client : 3 Number sample : 20 Epoch : 2   Ep loss : 1.5975923538208008
Client : 3 Number sample : 20 Epoch : 3   Ep loss : 1.2327528297901154
Client : 3 Number sample : 20 Epoch : 4   Ep loss : 1.0126863718032837
Client : 4 Number sample : 20 Epoch : 0   Ep loss : 2.2831435203552246
Client : 4 Number sample : 20 Epoch : 1   Ep loss : 1.9127076268196106
Client : 4 Number sample : 20 Epoch : 2   Ep loss : 1.521439254283905
Client : 4 Number sample : 20 Epoch : 3   Ep loss : 1.0867257118225098
Client : 4 Number sample : 20 Epoch : 4   Ep loss : 0.8725067973136902
Client : 5 Number sample : 20 Epoch : 0   Ep loss : 2.2995917797088623
Client : 5 Number sample : 20 Epoch : 1   Ep loss : 1.9415905475616455
Client : 5 Number sample : 20 Epoch : 2   Ep loss : 1.5885064005851746
Client : 0 Number sample : 20 Epoch : 0   Ep loss : 2.3145179748535156
Client : 5 Number sample : 20 Epoch : 3   Ep loss : 1.2293741106987
Client : 0 Number sample : 20 Epoch : 1   Ep loss : 1.9350629448890686
Client : 0 Number sample : 20 Epoch : 2   Ep loss : 1.5401086807250977
Client : 5 Number sample : 20 Epoch : 4   Ep loss : 0.9281195998191833
Client : 0 Number sample : 20 Epoch : 3   Ep loss : 1.1650676429271698
Client : 0 Number sample : 20 Epoch : 4   Ep loss : 0.8805927336215973
Client : 1 Number sample : 20 Epoch : 0   Ep loss : 2.302943468093872
Client : 1 Number sample : 20 Epoch : 1   Ep loss : 1.9034626483917236
Client : 1 Number sample : 20 Epoch : 2   Ep loss : 1.540928840637207
Client : 1 Number sample : 20 Epoch : 3   Ep loss : 1.1755647659301758
Client : 6 Number sample : 20 Epoch : 0   Ep loss : 2.2966020107269287
Client : 1 Number sample : 20 Epoch : 4   Ep loss : 0.8988779783248901
Client : 6 Number sample : 20 Epoch : 1   Ep loss : 1.8784252405166626
Client : 6 Number sample : 20 Epoch : 2   Ep loss : 1.512411653995514
Client : 8 Number sample : 20 Epoch : 0   Ep loss : 2.3732370138168335
Client : 6 Number sample : 20 Epoch : 3   Ep loss : 1.3100983500480652
Client : 8 Number sample : 20 Epoch : 1   Ep loss : 2.0052053332328796
Client : 8 Number sample : 20 Epoch : 2   Ep loss : 1.6455438733100891
Client : 6 Number sample : 20 Epoch : 4   Ep loss : 1.2002447247505188
Client : 8 Number sample : 20 Epoch : 3   Ep loss : 1.3485751748085022
Client : 8 Number sample : 20 Epoch : 4   Ep loss : 1.124432921409607
Client : 7 Number sample : 20 Epoch : 0   Ep loss : 2.456234931945801
Client : 9 Number sample : 20 Epoch : 0   Ep loss : 2.3583686351776123
Client : 7 Number sample : 20 Epoch : 1   Ep loss : 2.0544216632843018
Client : 9 Number sample : 20 Epoch : 1   Ep loss : 1.9366850852966309
Client : 9 Number sample : 20 Epoch : 2   Ep loss : 1.5385410785675049
Client : 7 Number sample : 20 Epoch : 2   Ep loss : 1.7013964653015137
Client : 9 Number sample : 20 Epoch : 3   Ep loss : 1.3442201018333435
Client : 7 Number sample : 20 Epoch : 3   Ep loss : 1.3866292238235474
Client : 9 Number sample : 20 Epoch : 4   Ep loss : 1.2668630480766296
Client : 7 Number sample : 20 Epoch : 4   Ep loss : 1.2461122274398804
Test :-------------------------------
100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 87.36it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 181.80it/s]
100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 78.45it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 135.60it/s]
100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 96.54it/s]
100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 82.25it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 128.45it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 138.62it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 193.47it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 108.42it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 120.51it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 303.20it/s]
100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 83.72it/s]
100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 78.69it/s]
100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 86.49it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 308.77it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 186.62it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 115.01it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 127.54it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 266.03it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 282.96it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 268.32it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 310.82it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 312.68it/s]
100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 80.32it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 293.66it/s]
100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 80.55it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 329.37it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 146.41it/s]
100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 95.68it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 152.67it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 214.27it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 110.30it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 158.49it/s]
100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 96.24it/s]
100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 90.05it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 160.62it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 126.50it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 145.56it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 151.03it/s]
100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 84.23it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 170.55it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 153.62it/s]
100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 107.30it/s]
100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 84.66it/s]







































































100%|████████████████████████████████████████▊| 312/313 [02:22<00:00,  1.77it/s]
Train :------------------------------

100%|█████████████████████████████████████████| 313/313 [02:23<00:00,  1.81it/s]
multiprocessing.pool.RemoteTraceback:
"""
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/usr/lib/python3.6/multiprocessing/pool.py", line 44, in mapstar
    return list(map(*args))
  File "/home/aimenext/workspace/dungnt/LongND-FL-Parallel-Computing/utils/trainer.py", line 16, in train
    model = model.to(device)
  File "/home/aimenext/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/home/aimenext/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/home/aimenext/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/home/aimenext/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
"""
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "train_SGD.py", line 231, in <module>
    main(args)
  File "train_SGD.py", line 162, in main
    for i in range(len(train_clients))
  File "/usr/lib/python3.6/multiprocessing/pool.py", line 266, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/usr/lib/python3.6/multiprocessing/pool.py", line 644, in get
    raise self._value
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
multiprocessing.pool.RemoteTraceback:
"""
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/usr/lib/python3.6/multiprocessing/pool.py", line 44, in mapstar
    return list(map(*args))
  File "/home/aimenext/workspace/dungnt/LongND-FL-Parallel-Computing/utils/trainer.py", line 16, in train
    model = model.to(device)
  File "/home/aimenext/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/home/aimenext/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/home/aimenext/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/home/aimenext/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
"""
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "train_SGD.py", line 231, in <module>
    main(args)
  File "train_SGD.py", line 162, in main
    for i in range(len(train_clients))
  File "/usr/lib/python3.6/multiprocessing/pool.py", line 266, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/usr/lib/python3.6/multiprocessing/pool.py", line 644, in get
    raise self._value
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.